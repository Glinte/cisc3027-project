{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50b5faae3d08552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:16:57.109938Z",
     "start_time": "2024-11-27T09:16:42.103123Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import project.utils\n",
    "# reload project\n",
    "from project.data.luna_dataset import Luna16Dataset\n",
    "from project.models.vnet import VNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efccb0644ec8306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VNet(num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08bf88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8256fd0556903c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:16:57.135495Z",
     "start_time": "2024-11-27T09:16:57.113945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e3bf47a20b1500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VNet(\n",
       "  (input_block): VNet_input_block(\n",
       "    (conv1): Conv3d(1, 16, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=16)\n",
       "  )\n",
       "  (down_block1): VNet_down_block(\n",
       "    (down_conv): Conv3d(16, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=32)\n",
       "    (convs): Sequential(\n",
       "      (0): Conv_in_stage(\n",
       "        (conv1): Conv3d(32, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (1): Conv_in_stage(\n",
       "        (conv1): Conv3d(32, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_block2): VNet_down_block(\n",
       "    (down_conv): Conv3d(32, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=64)\n",
       "    (convs): Sequential(\n",
       "      (0): Conv_in_stage(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (1): Conv_in_stage(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (2): Conv_in_stage(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_block3): VNet_down_block(\n",
       "    (down_conv): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=128)\n",
       "    (convs): Sequential(\n",
       "      (0): Conv_in_stage(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (1): Conv_in_stage(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (2): Conv_in_stage(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_block4): VNet_down_block(\n",
       "    (down_conv): Conv3d(128, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=256)\n",
       "    (convs): Sequential(\n",
       "      (0): Conv_in_stage(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (1): Conv_in_stage(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (2): Conv_in_stage(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_block1): VNet_up_block(\n",
       "    (up_conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=128)\n",
       "    (convs): Sequential(\n",
       "      (0): Conv_in_stage(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (1): Conv_in_stage(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (2): Conv_in_stage(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_block2): VNet_up_block(\n",
       "    (up_conv): ConvTranspose3d(256, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=64)\n",
       "    (convs): Sequential(\n",
       "      (0): Conv_in_stage(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (1): Conv_in_stage(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (2): Conv_in_stage(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_block3): VNet_up_block(\n",
       "    (up_conv): ConvTranspose3d(128, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=32)\n",
       "    (convs): Sequential(\n",
       "      (0): Conv_in_stage(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (1): Conv_in_stage(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_block4): VNet_up_block(\n",
       "    (up_conv): ConvTranspose3d(64, 16, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=16)\n",
       "    (convs): Sequential(\n",
       "      (0): Conv_in_stage(\n",
       "        (conv1): Conv3d(32, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_block): VNet_output_block(\n",
       "    (conv1): Conv3d(32, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "    (bn1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv3d(1, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (relu1): PReLU(num_parameters=1)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5866c3e691e11b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:20:14.228207Z",
     "start_time": "2024-11-27T09:20:14.182377Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import tv_tensors\n",
    "from project.config import PROJECT_ROOT\n",
    "\n",
    "class PadDepthTransform(nn.Module):\n",
    "    \"\"\"Pad the depth dimension of the input tensor to be divisible by 16.\"\"\"\n",
    "    def forward(self, img, mask) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Check if the number of depth dimensions is odd\n",
    "        if img.shape[1] % 16 != 0:\n",
    "            # Create a zero-filled padding with the same height and width\n",
    "            padding = torch.zeros(1, 16 - img.shape[1] % 16, *img.shape[2:], device=img.device, dtype=img.dtype)\n",
    "            # Concatenate the padding to the tensor\n",
    "            img = torch.cat([img, padding], dim=1)\n",
    "            mask = torch.cat([mask, padding], dim=1)\n",
    "        return tv_tensors.Image(img), tv_tensors.Mask(mask)\n",
    "    \n",
    "class Normalize3D(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super().__init__()\n",
    "        self.mean = torch.tensor(mean)\n",
    "        self.std = torch.tensor(std)\n",
    "        \n",
    "    def forward(self, img, mask) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        img = (img - self.mean) / self.std\n",
    "        return img, mask\n",
    "    \n",
    "class Resize3d(nn.Module):\n",
    "    def __init__(self, size: tuple[int, int, int]):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        \n",
    "    def forward(self, img: torch.Tensor, mask: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        img = nn.functional.interpolate(img.unsqueeze(0).float(), size=self.size, mode=\"trilinear\", align_corners=False).squeeze(0).long()\n",
    "        mask = nn.functional.interpolate(mask.unsqueeze(0).float(), size=self.size, mode=\"nearest\").squeeze(0).long()\n",
    "        return img, mask\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    Resize3d(size=(224, 224, 224)),\n",
    "    v2.ToDtype({tv_tensors.Image: torch.float32, tv_tensors.Mask: torch.int64, \"others\": None}),\n",
    "    Normalize3D(mean=-790.1, std=889.6),\n",
    "])\n",
    "\n",
    "luna16 = Luna16Dataset(root=PROJECT_ROOT / \"data/luna16\", transforms=transforms, train=True)\n",
    "luna16_base = Luna16Dataset(root=PROJECT_ROOT / \"data/luna16\", transforms=None, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d61630cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.5111), tensor(2.7530), tensor(1.2607))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luna16[0][0].min(), luna16[0][0].max(), luna16[0][0].float().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19603bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1126.5992)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luna16_base[0][0].float().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41fbe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(luna16[12][1].float() / 255).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46e9fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize = Resize3d((256, 256, 256))\n",
    "resize(*luna16_base[0])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d5fd35699d1861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:20:15.011885Z",
     "start_time": "2024-11-27T09:20:14.873682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           ...,\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111]],\n",
       " \n",
       "          [[-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           ...,\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111]],\n",
       " \n",
       "          [[-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           ...,\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           ...,\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111]],\n",
       " \n",
       "          [[-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           ...,\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111]],\n",
       " \n",
       "          [[-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           ...,\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111],\n",
       "           [-2.5111, -2.5111, -2.5111,  ..., -2.5111, -2.5111, -2.5111]]]]),\n",
       " tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "          [[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "          [[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "          [[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "          [[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms(*luna16_base[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5caef7402b15c5b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:20:16.091456Z",
     "start_time": "2024-11-27T09:20:16.087232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(luna16.masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "266e7527872f1060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:20:17.683145Z",
     "start_time": "2024-11-27T09:20:17.410295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 224, 224, 224]), torch.Size([1, 224, 224, 224]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luna16[0][0].shape, luna16[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345c2721b92e2910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:20:19.137440Z",
     "start_time": "2024-11-27T09:20:19.134873Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_train_loader = DataLoader(luna16, batch_size=1, shuffle=False)  # Batch size has to be 1 because each image has different depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d1f09e574496e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:20:41.951347Z",
     "start_time": "2024-11-27T09:20:19.781129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([  0, 255])\n",
      "tensor([  0, 255])\n",
      "tensor([  0, 255])\n",
      "tensor([0])\n",
      "tensor([  0, 255])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "for i, (data, target) in enumerate(luna_train_loader):\n",
    "    # print(data.shape, data.dtype)\n",
    "    # print(target.shape, target.dtype)\n",
    "    print(target.unique())\n",
    "    if i > 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b418988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = []\n",
    "# stds = []\n",
    "# base_loader = DataLoader(luna16_base, batch_size=1, shuffle=False)\n",
    "# for i, (data, target) in enumerate(base_loader):\n",
    "#     data = data.float()\n",
    "#     mean = data.mean()\n",
    "#     std = data.std()\n",
    "#     means.append(mean)\n",
    "#     stds.append(std)\n",
    "    \n",
    "# print(f\"Mean: {torch.stack(means).mean()}\")\n",
    "# print(f\"Std: {torch.stack(stds).mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77a95260bbc638c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:17:16.739191400Z",
     "start_time": "2024-11-27T09:16:32.638460Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload project\n",
    "from project.models.vnet import VNet\n",
    "from project.models.unet3d import UNet3D\n",
    "# import segmentation_models_3D as sm\n",
    "\n",
    "model = VNet(num_classes=2)\n",
    "# model = UNet3D(n_channels=1, n_classes=1)\n",
    "# model = sm.FPN(\n",
    "#     'densenet121',\n",
    "#     classes=1,\n",
    "#     activation='sigmoid'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45eff2184a4b5d30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:00:34.450553Z",
     "start_time": "2024-11-27T09:00:34.446245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22558182"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of parameters\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3548ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fcbfe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 224, 224])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mask_to_onehot(mask: torch.Tensor, num_classes: int) -> torch.Tensor:\n",
    "    mask = mask.unsqueeze(0)\n",
    "    mask_onehot = torch.zeros((num_classes, *mask.shape[1:]), device=mask.device)\n",
    "    mask_onehot.scatter_(0, mask, 1)\n",
    "    return mask_onehot\n",
    "\n",
    "mask_to_onehot(luna16[0][1], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703874940603b70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:02:46.202241Z",
     "start_time": "2024-11-27T09:02:45.941410Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: papetoast (papetoast-org1). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\cisc3027-project\\notebooks\\wandb\\run-20241127_234552-50wdn5ad</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/papetoast-org1/luna16/runs/50wdn5ad' target=\"_blank\">rosy-elevator-47</a></strong> to <a href='https://wandb.ai/papetoast-org1/luna16' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/papetoast-org1/luna16' target=\"_blank\">https://wandb.ai/papetoast-org1/luna16</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/papetoast-org1/luna16/runs/50wdn5ad' target=\"_blank\">https://wandb.ai/papetoast-org1/luna16/runs/50wdn5ad</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 224, 224, 224])\n",
      "Epoch: 0, Batch: 0, Loss: 0.6507939696311951\n",
      "torch.Size([1, 1, 224, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "\n",
    "import wandb\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "luna_train_loader = DataLoader(luna16, batch_size=1, shuffle=True)\n",
    "luna_test_loader = DataLoader(Luna16Dataset(root=PROJECT_ROOT / \"data\" / \"luna16\", transforms=transforms, train=False), batch_size=1, shuffle=False)\n",
    "\n",
    "# run = None\n",
    "run = wandb.init(\n",
    "    project=\"luna16\",\n",
    "    group=None,\n",
    "    job_type=\"train\",\n",
    "    config={\n",
    "        \"model\": \"VNet\",\n",
    "        \"loss_function\": criterion.__class__.__name__,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"scheduler\": scheduler.__class__.__name__,\n",
    "        \"lr\": 0.001,\n",
    "        \"batch_size\": 1,\n",
    "        \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "model.train().to(device)\n",
    "for epoch in range(10):\n",
    "    for i, (data, target) in enumerate(luna_train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        target = target / 255 # BCELoss expects float targets\n",
    "        print(output[:, 0:1, :, :, :].shape)\n",
    "        loss = criterion(output[:, 0:1, :, :, :], target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "        if run:\n",
    "            run.log({\"epoch\": epoch, \"batch\": i, \"train/loss\": loss.item()})\n",
    "    scheduler.step()\n",
    "    \n",
    "    losses = []\n",
    "    for i, (data, target) in enumerate(luna_test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        target = target / 255  # BCELoss expects float targets\n",
    "        loss = criterion(output, target.squeeze(0))\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    test_loss = sum(losses) / len(losses)  # Average loss over each image\n",
    "    print(f\"Epoch: {epoch}, Test loss: {test_loss}\")\n",
    "    if run:\n",
    "        run.log({\"epoch\": epoch, \"test/loss\": test_loss})\n",
    "\n",
    "if run:  \n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4b55bcea492149",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"unet3d_0.071.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8508d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(\"papetoast-org1/luna16/n8x2ixoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "070fa266",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.config[\"model\"] = \"UNet3D\"\n",
    "run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28097764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project.models.unet3d.UNet3D"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fd235f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "def visualize_ct_slices(ct_array):\n",
    "    \"\"\"\n",
    "    Visualize slices of a 3D CT scan interactively.\n",
    "    \n",
    "    Parameters:\n",
    "    - ct_array (numpy array): 3D array representing the CT scan.\n",
    "    \"\"\"\n",
    "    if ct_array is None:\n",
    "        print(\"No CT array to visualize.\")\n",
    "        return\n",
    "\n",
    "    def show_slice(slice_idx):\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(ct_array[slice_idx], cmap='gray')\n",
    "        plt.title(f\"Slice {slice_idx + 1}/{ct_array.shape[0]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    interact(show_slice, slice_idx=(0, ct_array.shape[0] - 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3e6643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "luna_test = Luna16Dataset(root=PROJECT_ROOT / \"data\" / \"luna16\", transforms=None, train=False)\n",
    "inputs, target = luna_test[0]\n",
    "# output = model(inputs.unsqueeze(0).to(device)).squeeze(0).squeeze(0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e5f3be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image([[[[-1020, -1008,  -982,  ...,  -950,  -977, -1006],\n",
       "         [-1013, -1016,  -997,  ...,  -965,  -978,  -980],\n",
       "         [-1002, -1013, -1017,  ...,  -966,  -969,  -973],\n",
       "         ...,\n",
       "         [ -965,  -953,  -897,  ...,  -415,  -579,  -736],\n",
       "         [-1000,  -917,  -860,  ...,  -913,  -968,  -994],\n",
       "         [ -936,  -840,  -877,  ..., -1012, -1016, -1024]],\n",
       "\n",
       "        [[ -992, -1001,  -973,  ...,  -975,  -982,  -996],\n",
       "         [ -985,  -979,  -972,  ...,  -950,  -993, -1015],\n",
       "         [-1019,  -998,  -969,  ...,  -989, -1004, -1015],\n",
       "         ...,\n",
       "         [ -895,  -894,  -875,  ...,  -504,  -621,  -783],\n",
       "         [ -908,  -865,  -824,  ...,  -967, -1017,  -987],\n",
       "         [ -876,  -814,  -844,  ..., -1024, -1024, -1024]],\n",
       "\n",
       "        [[ -972,  -978,  -988,  ..., -1008, -1005, -1013],\n",
       "         [ -955,  -964,  -970,  ...,  -989,  -979,  -978],\n",
       "         [ -962,  -963,  -954,  ...,  -980,  -989,  -997],\n",
       "         ...,\n",
       "         [ -981,  -842,  -805,  ...,  -443,  -673,  -944],\n",
       "         [ -905,  -812,  -883,  ...,  -843,  -918, -1006],\n",
       "         [ -855,  -852,  -927,  ..., -1024, -1011,  -960]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1016, -1000,  -963,  ...,  -984, -1004, -1018],\n",
       "         [-1007, -1012,  -978,  ...,  -995, -1012, -1024],\n",
       "         [-1002, -1003,  -984,  ..., -1002, -1020, -1021],\n",
       "         ...,\n",
       "         [ -878,  -890,  -936,  ...,   457,   432,   344],\n",
       "         [ -892,  -923,  -944,  ...,   411,   293,    99],\n",
       "         [ -924,  -912,  -912,  ...,    27,  -203,  -421]],\n",
       "\n",
       "        [[-1005,  -991,  -986,  ...,  -952,  -986, -1021],\n",
       "         [-1003,  -993,  -987,  ...,  -990, -1019, -1024],\n",
       "         [-1011,  -985,  -987,  ..., -1007, -1023, -1021],\n",
       "         ...,\n",
       "         [ -891,  -919,  -965,  ...,   444,   422,   347],\n",
       "         [ -927,  -940,  -954,  ...,   364,   242,    74],\n",
       "         [ -943,  -915,  -919,  ...,    -2,  -233,  -418]],\n",
       "\n",
       "        [[-1011, -1016, -1011,  ...,  -984,  -969, -1011],\n",
       "         [ -994, -1002, -1013,  ...,  -990, -1000, -1021],\n",
       "         [-1007,  -991, -1017,  ..., -1007, -1002, -1020],\n",
       "         ...,\n",
       "         [ -921,  -939,  -926,  ...,   414,   416,   347],\n",
       "         [ -914,  -911,  -892,  ...,   341,   232,    37],\n",
       "         [ -916,  -901,  -883,  ...,   -16,  -216,  -459]]]],\n",
       "      dtype=torch.int16, )"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c19caad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 224)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "481869f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "inputs = (inputs.squeeze(0).squeeze(0).numpy() * 0.026 + 0.023) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72da2462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.astype(np.uint8).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd64b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.squeeze(0).squeeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1272eaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a482400ebd4447598c73187d35d7040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=111, description='slice_idx', max=223), Output()), _dom_classes=('widgetâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_ct_slices(inputs.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36148e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
